{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e2dc91-bc24-43f8-84dd-a7b39568d9c1",
   "metadata": {},
   "source": [
    "### Demo 1: add a book to the Vector Store\n",
    "* using **LangChain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e56eb75a-0ec2-4758-9937-d28f60f32689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import oracledb\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# this is the class wrapping our Cohere embeddngs model\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "\n",
    "from config import EMBED_MODEL\n",
    "\n",
    "from config_private import (\n",
    "    DB_USER,\n",
    "    DB_PWD,\n",
    "    DB_SERVICE,\n",
    "    DB_HOST_IP,\n",
    "    COMPARTMENT_OCID,\n",
    "    ENDPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d37c0404-49be-44ef-9919-4289e3a95b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "    return len(encoding.encode(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0e1e6c5-b9f4-465d-b7d1-c248451c35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOK_NAME = \"covid19_treatment_guidelines.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee561f1f-3446-4539-b8bf-2e89502f1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(BOOK_NAME)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "\n",
    "pages = loader.load()\n",
    "chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28dd25ec-ccb7-4c66-af46-7d53422df8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 1755/1755 [00:00<00:00, 7707.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of token per chunk is 390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compute max token per chunk\n",
    "max_token = 0\n",
    "\n",
    "for chunk in tqdm(chunks):\n",
    "    n_tok = num_tokens_from_string(chunk.page_content)\n",
    "    if n_tok > max_token:\n",
    "        max_token = n_tok\n",
    "\n",
    "print(f\"The maximum number of token per chunk is {max_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "980d0afc-651a-4e62-a830-40e8ddacb0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OCIGenAIEmbeddings(\n",
    "    model_id=EMBED_MODEL,\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=COMPARTMENT_OCID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "877f2084-47ca-4a8e-aef8-7d4bb78a24f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 36/36 [00:38<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "embeddings = []\n",
    "txts = [chunk.page_content for chunk in chunks]\n",
    "\n",
    "for i in tqdm(range(0, len(txts), BATCH_SIZE)):\n",
    "    batch = txts[i : i + BATCH_SIZE]\n",
    "\n",
    "    # here we compute embeddings for a batch\n",
    "    embeddings_batch = embed_model.embed_documents(batch)\n",
    "    # add to the final list\n",
    "    embeddings.extend(embeddings_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76a67dc6-99f0-4b3b-a044-f981880567ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://generativeai.aiservice.us-chicago-1.oci.oraclecloud.com'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c597c-b469-4512-8126-0ad6c7e7c4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
